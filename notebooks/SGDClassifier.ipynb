{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab511405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joacosoulez/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467822272</td>\n",
       "      <td>love u guys r best</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467822273</td>\n",
       "      <td>im meting one besties tonight cant wait girl talk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467822283</td>\n",
       "      <td>thanks twiter ad sunisa got met hin show dc ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467822287</td>\n",
       "      <td>sick realy cheap hurts much eat real fod plus ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467822293</td>\n",
       "      <td>efect everyone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids                                              Tweet  label\n",
       "0  1467822272                                 love u guys r best      0\n",
       "1  1467822273  im meting one besties tonight cant wait girl talk      0\n",
       "2  1467822283  thanks twiter ad sunisa got met hin show dc ar...      0\n",
       "3  1467822287  sick realy cheap hurts much eat real fod plus ...      0\n",
       "4  1467822293                                     efect everyone      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "prueba3 = pd.read_csv('../raw_data/df_limpio_con_df_lunes_limpio.csv')\n",
    "prueba3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd7a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba3 = prueba3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc88e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(prueba3['Tweet'], prueba3['label'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17454c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(...\n",
       "                ('elf',\n",
       "                 SGDClassifier(alpha=0.1, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "sed = Pipeline([('vect', TfidfVectorizer()),\n",
    "                ('tfidf',TfidfTransformer()),\n",
    "                ('elf', SGDClassifier (loss='hinge', penalty='l2', alpha=1/10, random_state=42,n_jobs= -1))\n",
    "                 ])\n",
    "sed.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "632589be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9675869228460896"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sed.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac013a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sed.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aa5475f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bj/ndgdqzgj6qgd9y613qph_m180000gn/T/ipykernel_55841/2431288899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "#accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "278fb088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                   input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                   min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                   smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                   sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=None, use_idf=True, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('elf',\n",
       "   SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
       "                 epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "                 learning_rate='optimal', loss='hinge', max_iter=50,\n",
       "                 n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "                 random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                 verbose=0, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'vect': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                 min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'elf': SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
       "               epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "               learning_rate='optimal', loss='hinge', max_iter=50,\n",
       "               n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "               random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "               verbose=0, warm_start=False),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.float64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__norm': 'l2',\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__smooth_idf': True,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__sublinear_tf': False,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': None,\n",
       " 'vect__use_idf': True,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'elf__alpha': 0.1,\n",
       " 'elf__average': False,\n",
       " 'elf__class_weight': None,\n",
       " 'elf__early_stopping': False,\n",
       " 'elf__epsilon': 0.1,\n",
       " 'elf__eta0': 0.0,\n",
       " 'elf__fit_intercept': True,\n",
       " 'elf__l1_ratio': 0.15,\n",
       " 'elf__learning_rate': 'optimal',\n",
       " 'elf__loss': 'hinge',\n",
       " 'elf__max_iter': 50,\n",
       " 'elf__n_iter_no_change': 5,\n",
       " 'elf__n_jobs': None,\n",
       " 'elf__penalty': 'l2',\n",
       " 'elf__power_t': 0.5,\n",
       " 'elf__random_state': 42,\n",
       " 'elf__shuffle': True,\n",
       " 'elf__tol': 0.001,\n",
       " 'elf__validation_fraction': 0.1,\n",
       " 'elf__verbose': 0,\n",
       " 'elf__warm_start': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sed.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
