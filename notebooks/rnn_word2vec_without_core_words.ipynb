{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5166412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3182e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/lucaspancotto/code/JoacoSoulez/mental_health_first_aid_evaluation/data/twitter_reddit_text.csv'\n",
    "core_path = '/home/lucaspancotto/code/JoacoSoulez/mental_health_first_aid_evaluation/data/sorted_coefs_naivebayes_twitterreddit.csv'\n",
    "data= pd.read_csv(f'{path}')\n",
    "core_data = pd.read_csv(f'{core_path}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6e1d8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feel</td>\n",
       "      <td>-4.990164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depress</td>\n",
       "      <td>-5.006754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>-5.237492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want</td>\n",
       "      <td>-5.350858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get</td>\n",
       "      <td>-5.560917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0         0\n",
       "0       feel -4.990164\n",
       "1    depress -5.006754\n",
       "2       like -5.237492\n",
       "3       want -5.350858\n",
       "4        get -5.560917"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef669d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_words = core_data['Unnamed: 0'].to_list()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1024c2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(core_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "758f30d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lay bed hour point back pain get work minut cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dlitedaili dont play wouldnt want anyth world</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rewebcoach hey handsom time get day go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>get readi tenni maryyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hear song band almost never play favourit radi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         clean_text  label\n",
       "0           0  lay bed hour point back pain get work minut cl...      1\n",
       "1           1      dlitedaili dont play wouldnt want anyth world      0\n",
       "2           2             rewebcoach hey handsom time get day go      0\n",
       "3           3                             get readi tenni maryyi      0\n",
       "4           4  hear song band almost never play favourit radi...      0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4d775eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c4ce6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_core_words(txt):\n",
    "    txt = word_tokenize(str(txt))\n",
    "    txt = ' '.join(word for word in txt if not word in core_words)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83365f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my goodness oh'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_core_words('depress my goodness oh fuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92a87f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stopped = data.clean_text.apply(stop_core_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b8188c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        lay bed hour minut clock motiv liter stare put...\n",
       "1                       dlitedaili dont play wouldnt world\n",
       "2                                   rewebcoach hey handsom\n",
       "3                                       readi tenni maryyi\n",
       "4           hear song band almost play favourit radio mood\n",
       "                               ...                        \n",
       "25363                           honestli convers post grad\n",
       "25364           ye ye thank god u answer prayer asap owe u\n",
       "25365                                        play game lol\n",
       "25366    late l high stress interview dream today despi...\n",
       "25367                 thank burghrealtor pghjen pie remend\n",
       "Name: clean_text, Length: 25368, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7978714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_train 17757 length of X_test 7611 length of y_train 17757 length of y_test 7611\n"
     ]
    }
   ],
   "source": [
    "X = data_stopped\n",
    "y = data.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y ,test_size = 0.3 )\n",
    "print('length of X_train',len(X_train), 'length of X_test',len(X_test), 'length of y_train',len(y_train), 'length of y_test',len(y_test))\n",
    "\n",
    "X_train = [word_tokenize(str(_)) for _ in X_train]\n",
    "X_test = [word_tokenize(str(_)) for _ in X_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7363a2cb",
   "metadata": {},
   "source": [
    "# embed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d8bf7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line trains an entire embedding for the words in your train set\n",
    "word2vec = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=5)\n",
    "\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "def embedding(word2vec, sentences):\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "    # $CHALLENGIFY_END\n",
    "    \n",
    "X_train = embedding(word2vec, X_train)\n",
    "X_test = embedding(word2vec, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4261a131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:11:08.386038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-09 15:11:08.386088: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#cortamos en 400 words\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train, dtype='float', padding='post', maxlen= 400,truncating= 'post')\n",
    "X_test_pad = pad_sequences(X_test, dtype='float', padding='post', maxlen = 400 , truncating = 'post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3314baa4",
   "metadata": {},
   "source": [
    "# model rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10e60b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:18:12.495446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-09 15:18:12.497273: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-09 15:18:12.499046: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-QMHRL2V): /proc/driver/nvidia/version does not exist\n",
      "2022-03-09 15:18:12.532739: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(20, activation='tanh'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy', 'AUC','Precision','Recall'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c3ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:18:47.977076: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1988640000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "389/389 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.8999 - auc: 0.9532 - precision: 0.9283 - recall: 0.8659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:23:25.034531: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 852480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 133s 302ms/step - loss: 0.2598 - accuracy: 0.8999 - auc: 0.9532 - precision: 0.9283 - recall: 0.8659 - val_loss: 0.2084 - val_accuracy: 0.9244 - val_auc: 0.9670 - val_precision: 0.9546 - val_recall: 0.8924\n",
      "Epoch 2/100\n",
      "389/389 [==============================] - 111s 285ms/step - loss: 0.2091 - accuracy: 0.9187 - auc: 0.9672 - precision: 0.9503 - recall: 0.8830 - val_loss: 0.2399 - val_accuracy: 0.9125 - val_auc: 0.9621 - val_precision: 0.9797 - val_recall: 0.8440\n",
      "Epoch 3/100\n",
      "389/389 [==============================] - 114s 292ms/step - loss: 0.2009 - accuracy: 0.9220 - auc: 0.9701 - precision: 0.9542 - recall: 0.8857 - val_loss: 0.1954 - val_accuracy: 0.9279 - val_auc: 0.9704 - val_precision: 0.9615 - val_recall: 0.8928\n",
      "Epoch 4/100\n",
      "389/389 [==============================] - 112s 288ms/step - loss: 0.1978 - accuracy: 0.9217 - auc: 0.9710 - precision: 0.9520 - recall: 0.8875 - val_loss: 0.1921 - val_accuracy: 0.9259 - val_auc: 0.9724 - val_precision: 0.9505 - val_recall: 0.8999\n",
      "Epoch 5/100\n",
      "389/389 [==============================] - 107s 275ms/step - loss: 0.1935 - accuracy: 0.9243 - auc: 0.9721 - precision: 0.9563 - recall: 0.8885 - val_loss: 0.1908 - val_accuracy: 0.9277 - val_auc: 0.9730 - val_precision: 0.9521 - val_recall: 0.9021\n",
      "Epoch 6/100\n",
      "389/389 [==============================] - 113s 290ms/step - loss: 0.1911 - accuracy: 0.9243 - auc: 0.9729 - precision: 0.9551 - recall: 0.8898 - val_loss: 0.1976 - val_accuracy: 0.9234 - val_auc: 0.9732 - val_precision: 0.9354 - val_recall: 0.9110\n",
      "Epoch 7/100\n",
      "389/389 [==============================] - 111s 284ms/step - loss: 0.1890 - accuracy: 0.9252 - auc: 0.9734 - precision: 0.9561 - recall: 0.8906 - val_loss: 0.1864 - val_accuracy: 0.9294 - val_auc: 0.9737 - val_precision: 0.9554 - val_recall: 0.9021\n",
      "Epoch 8/100\n",
      "389/389 [==============================] - 106s 271ms/step - loss: 0.1866 - accuracy: 0.9253 - auc: 0.9743 - precision: 0.9563 - recall: 0.8906 - val_loss: 0.1944 - val_accuracy: 0.9251 - val_auc: 0.9733 - val_precision: 0.9403 - val_recall: 0.9092\n",
      "Epoch 9/100\n",
      "389/389 [==============================] - 101s 260ms/step - loss: 0.1849 - accuracy: 0.9261 - auc: 0.9746 - precision: 0.9562 - recall: 0.8924 - val_loss: 0.1858 - val_accuracy: 0.9300 - val_auc: 0.9740 - val_precision: 0.9573 - val_recall: 0.9013\n",
      "Epoch 10/100\n",
      "389/389 [==============================] - 101s 260ms/step - loss: 0.1828 - accuracy: 0.9280 - auc: 0.9752 - precision: 0.9583 - recall: 0.8943 - val_loss: 0.1862 - val_accuracy: 0.9294 - val_auc: 0.9740 - val_precision: 0.9605 - val_recall: 0.8969\n",
      "Epoch 11/100\n",
      "389/389 [==============================] - 111s 285ms/step - loss: 0.1803 - accuracy: 0.9279 - auc: 0.9756 - precision: 0.9583 - recall: 0.8941 - val_loss: 0.1909 - val_accuracy: 0.9259 - val_auc: 0.9745 - val_precision: 0.9401 - val_recall: 0.9110\n",
      "Epoch 12/100\n",
      "389/389 [==============================] - 130s 334ms/step - loss: 0.1786 - accuracy: 0.9304 - auc: 0.9764 - precision: 0.9609 - recall: 0.8967 - val_loss: 0.1815 - val_accuracy: 0.9315 - val_auc: 0.9750 - val_precision: 0.9648 - val_recall: 0.8969\n",
      "Epoch 13/100\n",
      "185/389 [=============>................] - ETA: 56s - loss: 0.1743 - accuracy: 0.9311 - auc: 0.9774 - precision: 0.9577 - recall: 0.8999"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "history_fit = model.fit(X_train_pad, y_train, \n",
    "          batch_size = 32,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es],\n",
    "          verbose = 1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d69b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=200)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "    ax1.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax1.grid(axis=\"y\",linewidth=0.5)    \n",
    "    \n",
    "    ax2.plot(history.history['accuracy'])\n",
    "    ax2.plot(history.history['val_accuracy'])\n",
    "    ax2.set_title('accuracy')\n",
    "    ax2.set_ylabel('accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=20)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    ax2.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax2.grid(axis=\"y\",linewidth=0.5)    \n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
