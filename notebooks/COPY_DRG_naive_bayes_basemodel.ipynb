{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6054c8d2",
   "metadata": {},
   "source": [
    "# Bring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526689db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93cdc1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please type your path to the database: /Users/danielriojas/Documents/Random_2022/df_limpio.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielriojas/.pyenv/versions/3.8.12/envs/lewagon_current/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467822272</td>\n",
       "      <td>love u guys r best</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467822273</td>\n",
       "      <td>im meting one besties tonight cant wait girl talk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467822283</td>\n",
       "      <td>thanks twiter ad sunisa got met hin show dc ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467822287</td>\n",
       "      <td>sick realy cheap hurts much eat real fod plus ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467822293</td>\n",
       "      <td>efect everyone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids                                              Tweet  label\n",
       "0  1467822272                                 love u guys r best      0\n",
       "1  1467822273  im meting one besties tonight cant wait girl talk      0\n",
       "2  1467822283  thanks twiter ad sunisa got met hin show dc ar...      0\n",
       "3  1467822287  sick realy cheap hurts much eat real fod plus ...      0\n",
       "4  1467822293                                     efect everyone      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bring your data!\n",
    "path = input('please type your path to the database: ')\n",
    "data = pd.read_csv(f'{path}')\n",
    "data.head()\n",
    "\n",
    "#/Users/danielriojas/Documents/Random_2022/clean_depressionvspossitive.csv\n",
    "#/Users/danielriojas/Documents/Random_2022/df_limpio.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "670627dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = data[data.label == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a35ff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b64541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_data = data[data.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9ddb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "097e7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_positive_data = positive_data.sample( n  = 2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749314ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_positive_data.append(depression_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d271f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data =  sample_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ea2ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4690, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "538b89e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose the text column of your data: Tweet\n",
      "choose the target column of your data: label\n"
     ]
    }
   ],
   "source": [
    "text_col = input('choose the text column of your data: ')\n",
    "X = sample_data[f'{text_col}']\n",
    "\n",
    "target_col = input('choose the target column of your data: ')\n",
    "y = sample_data[f'{target_col}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecfccc",
   "metadata": {},
   "source": [
    "# naive bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd01e52",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56419c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV , cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84a04a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(ngram_range=(4,5))\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a64ea47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801387    k debt vs k hapines vs depresion emoji face te...\n",
       "559241                                        thanks wishes\n",
       "800383    depresion anxiety constant state remembering e...\n",
       "801434                           depresion let work healthy\n",
       "800084    uncle tupelo depresion demos rsd record store ...\n",
       "                                ...                        \n",
       "800929    lack sexual interest symptom depresionme expla...\n",
       "800333    last count received nearly mesages people teli...\n",
       "745814                                      welcome namaste\n",
       "801739    sigh mum wrong tiredmum tired even done anythi...\n",
       "220491    aha pet siting bles ben nan hospital realy lis...\n",
       "Name: Tweet, Length: 4690, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.apply(str)\n",
    "#X.apply(word_tokenize)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1177ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = tfid.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.DataFrame(X.toarray(),columns = tfid.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "110bcc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "simple_cross_val_recall = cross_val_score(nb, vector , y , scoring= 'recall', cv=3,\n",
    "               n_jobs = -1 , verbose = 1\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b754447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the recall:  0.12199641310624344\n"
     ]
    }
   ],
   "source": [
    "print('the recall: ' ,np.mean(simple_cross_val_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c09e2822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "simple_cross_val_accuracy = cross_val_score(nb, vector , y , scoring= 'accuracy', cv=3,\n",
    "               n_jobs = -1 , verbose = 1\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbaf1aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy:  0.5164125484959903\n"
     ]
    }
   ],
   "source": [
    "print('the accuracy: ' , np.mean(simple_cross_val_accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3649cb0",
   "metadata": {},
   "source": [
    "## grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fa522e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801387    k debt vs k hapines vs depresion emoji face te...\n",
       "559241                                        thanks wishes\n",
       "800383    depresion anxiety constant state remembering e...\n",
       "801434                           depresion let work healthy\n",
       "800084    uncle tupelo depresion demos rsd record store ...\n",
       "                                ...                        \n",
       "800929    lack sexual interest symptom depresionme expla...\n",
       "800333    last count received nearly mesages people teli...\n",
       "745814                                      welcome namaste\n",
       "801739    sigh mum wrong tiredmum tired even done anythi...\n",
       "220491    aha pet siting bles ben nan hospital realy lis...\n",
       "Name: Tweet, Length: 4690, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfid2 = TfidfVectorizer(ngram_range=(4,5))\n",
    "nb2 = MultinomialNB()\n",
    "X = X.apply(str)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "760852be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('TfidfVectorizer', tfid2),\n",
    "    ('MultinomialNB()' , nb2)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ea64c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('TfidfVectorizer',\n",
       "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                   input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                   min_df=1, ngram_range=(4, 5), norm='l2', preprocessor=None,\n",
       "                   smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                   sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=None, use_idf=True, vocabulary=None)),\n",
       "  ('MultinomialNB()',\n",
       "   MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       " 'verbose': False,\n",
       " 'TfidfVectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                 input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                 min_df=1, ngram_range=(4, 5), norm='l2', preprocessor=None,\n",
       "                 smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                 sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'MultinomialNB()': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       " 'TfidfVectorizer__analyzer': 'word',\n",
       " 'TfidfVectorizer__binary': False,\n",
       " 'TfidfVectorizer__decode_error': 'strict',\n",
       " 'TfidfVectorizer__dtype': numpy.float64,\n",
       " 'TfidfVectorizer__encoding': 'utf-8',\n",
       " 'TfidfVectorizer__input': 'content',\n",
       " 'TfidfVectorizer__lowercase': True,\n",
       " 'TfidfVectorizer__max_df': 1.0,\n",
       " 'TfidfVectorizer__max_features': None,\n",
       " 'TfidfVectorizer__min_df': 1,\n",
       " 'TfidfVectorizer__ngram_range': (4, 5),\n",
       " 'TfidfVectorizer__norm': 'l2',\n",
       " 'TfidfVectorizer__preprocessor': None,\n",
       " 'TfidfVectorizer__smooth_idf': True,\n",
       " 'TfidfVectorizer__stop_words': None,\n",
       " 'TfidfVectorizer__strip_accents': None,\n",
       " 'TfidfVectorizer__sublinear_tf': False,\n",
       " 'TfidfVectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'TfidfVectorizer__tokenizer': None,\n",
       " 'TfidfVectorizer__use_idf': True,\n",
       " 'TfidfVectorizer__vocabulary': None,\n",
       " 'MultinomialNB()__alpha': 1.0,\n",
       " 'MultinomialNB()__class_prior': None,\n",
       " 'MultinomialNB()__fit_prior': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97bb330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid = {\n",
    "    'TfidfVectorizer__ngram_range': [(1,2) , (2,3), (3,4),(4, 5)],\n",
    "    'MultinomialNB()__alpha': [0.1 , 0.5 , 1.0]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84ce48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_recall= GridSearchCV(pipe,\n",
    "    pipe_grid,\n",
    "    scoring='recall',\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc927baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('TfidfVectorizer',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(4, 5),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None...\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('MultinomialNB()',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'MultinomialNB()__alpha': [0.1, 0.5, 1.0],\n",
       "                         'TfidfVectorizer__ngram_range': [(1, 2), (2, 3),\n",
       "                                                          (3, 4), (4, 5)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_recall.fit(X , y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3edd241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best params for recall:  {'MultinomialNB()__alpha': 1.0, 'TfidfVectorizer__ngram_range': (1, 2)}\n",
      "the best recall score:  0.9628981359286463\n"
     ]
    }
   ],
   "source": [
    "print('the best params for recall: ',search_recall.best_params_)\n",
    "print('the best recall score: ' , search_recall.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cc21a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_recall = search_recall.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97a5109d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_recall[\"MultinomialNB()\"].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ebcecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_accuracy= GridSearchCV(pipe,\n",
    "    pipe_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7067f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('TfidfVectorizer',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(4, 5),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None...\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('MultinomialNB()',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'MultinomialNB()__alpha': [0.1, 0.5, 1.0],\n",
       "                         'TfidfVectorizer__ngram_range': [(1, 2), (2, 3),\n",
       "                                                          (3, 4), (4, 5)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_accuracy.fit(X , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d33c2450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best params for accuracy:  {'MultinomialNB()__alpha': 0.5, 'TfidfVectorizer__ngram_range': (1, 2)}\n",
      "the best accuracy score:  0.9040507549093242\n"
     ]
    }
   ],
   "source": [
    "print('the best params for accuracy: ',search_accuracy.best_params_)\n",
    "print('the best accuracy score: ' , search_accuracy.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325125af",
   "metadata": {},
   "source": [
    "# testeo y analisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'MultinomialNB()__alpha': 1.0, 'TfidfVectorizer__ngram_range': (1, 2)}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02a0ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid3 = TfidfVectorizer(ngram_range=(1,2))\n",
    "nb3 = MultinomialNB(alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "619fab53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfid3.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c3e6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector3 = tfid3.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da103aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab',\n",
       " 'ab chalenges',\n",
       " 'ab months',\n",
       " 'ab riper',\n",
       " 'abandoned',\n",
       " 'abandoned heartbroken',\n",
       " 'abatement',\n",
       " 'abatement depresion',\n",
       " 'abdula',\n",
       " 'abdula shaikh',\n",
       " 'abe',\n",
       " 'abe lincoln',\n",
       " 'abel',\n",
       " 'abel love',\n",
       " 'ability',\n",
       " 'ability manage',\n",
       " 'able',\n",
       " 'able acomplish',\n",
       " 'able aford',\n",
       " 'able catch',\n",
       " 'able come',\n",
       " 'able dry',\n",
       " 'able get',\n",
       " 'able leave',\n",
       " 'able pay',\n",
       " 'able pul',\n",
       " 'able runing',\n",
       " 'able slepdepresion',\n",
       " 'able take',\n",
       " 'able translate',\n",
       " 'able turn',\n",
       " 'able wear',\n",
       " 'able without',\n",
       " 'able work',\n",
       " 'able write',\n",
       " 'abnormal',\n",
       " 'abnormal functional',\n",
       " 'aboard',\n",
       " 'aboard email',\n",
       " 'abort',\n",
       " 'abort child',\n",
       " 'abortion',\n",
       " 'abortion child',\n",
       " 'abortion considered',\n",
       " 'abraham',\n",
       " 'abraham lincoln',\n",
       " 'abroad',\n",
       " 'abroad depresion',\n",
       " 'abs',\n",
       " 'abs dayum',\n",
       " 'absence',\n",
       " 'absence cedar',\n",
       " 'absolut',\n",
       " 'absolut keine',\n",
       " 'absolutely',\n",
       " 'absolutely cream',\n",
       " 'absolutely due',\n",
       " 'absolutely impresed',\n",
       " 'absolutely love',\n",
       " 'absolutely nite',\n",
       " 'absolutely reason',\n",
       " 'absolutely shit',\n",
       " 'absolutely stuning',\n",
       " 'absolutely terible',\n",
       " 'absolutely true',\n",
       " 'absorbed',\n",
       " 'absorbed wod',\n",
       " 'abt',\n",
       " 'abt al',\n",
       " 'abt blk',\n",
       " 'abt depresion',\n",
       " 'abt dis',\n",
       " 'abt drug',\n",
       " 'abt fre',\n",
       " 'abt recovery',\n",
       " 'abt tel',\n",
       " 'abt voting',\n",
       " 'abundance',\n",
       " 'abundance junk',\n",
       " 'abuse',\n",
       " 'abuse alochol',\n",
       " 'abuse anxiety',\n",
       " 'abuse bulying',\n",
       " 'abuse depresion',\n",
       " 'abuse etc',\n",
       " 'abuse low',\n",
       " 'abuse old',\n",
       " 'abuse rape',\n",
       " 'abuse survivor',\n",
       " 'abuse ur',\n",
       " 'abused',\n",
       " 'abused suport',\n",
       " 'abused tenager',\n",
       " 'ac',\n",
       " 'ac mcan',\n",
       " 'ac went',\n",
       " 'academic',\n",
       " 'academic presure',\n",
       " 'academy',\n",
       " 'academy lol',\n",
       " 'acb',\n",
       " 'acb aph',\n",
       " 'ace',\n",
       " 'ace born',\n",
       " 'acent',\n",
       " 'acent folow',\n",
       " 'acept',\n",
       " 'acept experience',\n",
       " 'acept otherwise',\n",
       " 'acept refuse',\n",
       " 'acept stop',\n",
       " 'aceptance',\n",
       " 'aceptance phase',\n",
       " 'aceptance semi',\n",
       " 'aceptancei',\n",
       " 'aceptancei stil',\n",
       " 'acepted',\n",
       " 'acepted cuz',\n",
       " 'acepted ubuntu',\n",
       " 'acepting',\n",
       " 'acepting request',\n",
       " 'aces',\n",
       " 'aces drugs',\n",
       " 'aces mental',\n",
       " 'acesory',\n",
       " 'acesory lmao',\n",
       " 'ach',\n",
       " 'ach caught',\n",
       " 'ache',\n",
       " 'ache quot',\n",
       " 'ache sore',\n",
       " 'aches',\n",
       " 'aches sleping',\n",
       " 'achieve',\n",
       " 'achieve dreams',\n",
       " 'achieve get',\n",
       " 'achieve goals',\n",
       " 'achievements',\n",
       " 'achievements duplicated',\n",
       " 'achiles',\n",
       " 'achiles tendon',\n",
       " 'achive',\n",
       " 'achive goals',\n",
       " 'acid',\n",
       " 'acid track',\n",
       " 'acident',\n",
       " 'acident droped',\n",
       " 'acident instead',\n",
       " 'acident sufering',\n",
       " 'acidentaly',\n",
       " 'acidentaly made',\n",
       " 'acidentaly se',\n",
       " 'acidentaly tok',\n",
       " 'acing',\n",
       " 'acing al',\n",
       " 'acne',\n",
       " 'acne ben',\n",
       " 'acne causing',\n",
       " 'acne cured',\n",
       " 'acne depresion',\n",
       " 'acompanied',\n",
       " 'acompanied many',\n",
       " 'acomplish',\n",
       " 'acomplish since',\n",
       " 'acomplish something',\n",
       " 'acomplished',\n",
       " 'acomplished finished',\n",
       " 'acomplishments',\n",
       " 'acomplishments one',\n",
       " 'acording',\n",
       " 'acording cdcp',\n",
       " 'acording last',\n",
       " 'acording new',\n",
       " 'acording someone',\n",
       " 'acount',\n",
       " 'acount depresion',\n",
       " 'acount quenxlaray',\n",
       " 'acount shiped',\n",
       " 'acount suport',\n",
       " 'acount without',\n",
       " 'acount years',\n",
       " 'acountability',\n",
       " 'acountability transparency',\n",
       " 'acounts',\n",
       " 'acros',\n",
       " 'acros hapines',\n",
       " 'acros rom',\n",
       " 'acros tinternet',\n",
       " 'acros world',\n",
       " 'acrylic',\n",
       " 'acrylic charms',\n",
       " 'act',\n",
       " 'act forsure',\n",
       " 'act like',\n",
       " 'act personalities',\n",
       " 'act self',\n",
       " 'act thoughts',\n",
       " 'act weird',\n",
       " 'acted',\n",
       " 'acted like',\n",
       " 'acted pre',\n",
       " 'acted violently',\n",
       " 'acting',\n",
       " 'acting depresion',\n",
       " 'acting like',\n",
       " 'acting sily',\n",
       " 'action',\n",
       " 'action gain',\n",
       " 'action steps',\n",
       " 'actions',\n",
       " 'actions atention',\n",
       " 'actions know',\n",
       " 'activated',\n",
       " 'activation',\n",
       " 'activation much',\n",
       " 'active',\n",
       " 'active helps',\n",
       " 'active lately',\n",
       " 'active leser',\n",
       " 'active lifestyle',\n",
       " 'active motivation',\n",
       " 'active phase',\n",
       " 'active players',\n",
       " 'active received',\n",
       " 'active recent',\n",
       " 'active rejection',\n",
       " 'active robust',\n",
       " 'activist',\n",
       " 'activist cow',\n",
       " 'activities',\n",
       " 'activities even',\n",
       " 'activity',\n",
       " 'activity ben',\n",
       " 'activity decreases',\n",
       " 'activity incident',\n",
       " 'activity moments',\n",
       " 'activity protect',\n",
       " 'activity receptors',\n",
       " 'activity serotonin',\n",
       " 'activity wil',\n",
       " 'actor',\n",
       " 'actor regret',\n",
       " 'actor verne',\n",
       " 'actors',\n",
       " 'actors symptoms',\n",
       " 'acts',\n",
       " 'acts injustice',\n",
       " 'acts next',\n",
       " 'actual',\n",
       " 'actual chemical',\n",
       " 'actual definition',\n",
       " 'actual depresion',\n",
       " 'actual father',\n",
       " 'actual friends',\n",
       " 'actual imbalance',\n",
       " 'actual interaction',\n",
       " 'actual picture',\n",
       " 'actual vile',\n",
       " 'actualy',\n",
       " 'actualy believe',\n",
       " 'actualy bipolar',\n",
       " 'actualy changed',\n",
       " 'actualy comit',\n",
       " 'actualy cures',\n",
       " 'actualy curing',\n",
       " 'actualy edits',\n",
       " 'actualy everyone',\n",
       " 'actualy fel',\n",
       " 'actualy fighting',\n",
       " 'actualy great',\n",
       " 'actualy hapy',\n",
       " 'actualy helped',\n",
       " 'actualy helps',\n",
       " 'actualy high',\n",
       " 'actualy idea',\n",
       " 'actualy im',\n",
       " 'actualy like',\n",
       " 'actualy literaly',\n",
       " 'actualy makes',\n",
       " 'actualy making',\n",
       " 'actualy one',\n",
       " 'actualy por',\n",
       " 'actualy prety',\n",
       " 'actualy real',\n",
       " 'actualy realised',\n",
       " 'actualy realy',\n",
       " 'actualy something',\n",
       " 'actualy strugle',\n",
       " 'actualy taned',\n",
       " 'actualy thought',\n",
       " 'actualy understands',\n",
       " 'actualy wil',\n",
       " 'actualy yes',\n",
       " 'acurate',\n",
       " 'acurate train',\n",
       " 'acurately',\n",
       " 'acurately media',\n",
       " 'acused',\n",
       " 'acused crap',\n",
       " 'acute',\n",
       " 'acute depresion',\n",
       " 'ad',\n",
       " 'ad airing',\n",
       " 'ad anchor',\n",
       " 'ad anxiety',\n",
       " 'ad banished',\n",
       " 'ad depresion',\n",
       " 'ad download',\n",
       " 'ad eg',\n",
       " 'ad everyone',\n",
       " 'ad hominem',\n",
       " 'ad list',\n",
       " 'ad mental',\n",
       " 'ad pain',\n",
       " 'ad severe',\n",
       " 'ad tech',\n",
       " 'ad thisf',\n",
       " 'ad ws',\n",
       " 'ad xvickyx',\n",
       " 'adam',\n",
       " 'adam eve',\n",
       " 'adam lambert',\n",
       " 'adam sure',\n",
       " 'adam thanx',\n",
       " 'adams',\n",
       " 'adams family',\n",
       " 'aded',\n",
       " 'aded diagnostic',\n",
       " 'aded dificulties',\n",
       " 'aded nst',\n",
       " 'aded sped',\n",
       " 'aded video',\n",
       " 'aderal',\n",
       " 'adhd',\n",
       " 'adhd afects',\n",
       " 'adhd ben',\n",
       " 'adhd depresion',\n",
       " 'adhd get',\n",
       " 'adhd one',\n",
       " 'adhd sad',\n",
       " 'adict',\n",
       " 'adict criminal',\n",
       " 'adict inspiration',\n",
       " 'adicted',\n",
       " 'adicted entertained',\n",
       " 'adicted game',\n",
       " 'adicted like',\n",
       " 'adicted video',\n",
       " 'adiction',\n",
       " 'adiction anxiety',\n",
       " 'adiction blend',\n",
       " 'adiction chronic',\n",
       " 'adiction daily',\n",
       " 'adiction depresion',\n",
       " 'adiction domestic',\n",
       " 'adiction dont',\n",
       " 'adiction eating',\n",
       " 'adiction god',\n",
       " 'adiction hotline',\n",
       " 'adiction one',\n",
       " 'adiction psychoses',\n",
       " 'adiction right',\n",
       " 'adiction selective',\n",
       " 'adictive',\n",
       " 'adictive god',\n",
       " 'ading',\n",
       " 'ading stuf',\n",
       " 'ading thank',\n",
       " 'adios',\n",
       " 'adios mi',\n",
       " 'adipavi',\n",
       " 'adition',\n",
       " 'adition exercise',\n",
       " 'aditional',\n",
       " 'aditional forget',\n",
       " 'adjusting',\n",
       " 'adjusting know',\n",
       " 'administration',\n",
       " 'administration lead',\n",
       " 'admiral',\n",
       " 'admiral jackson',\n",
       " 'admire',\n",
       " 'admire sharing',\n",
       " 'admit',\n",
       " 'admit continue',\n",
       " 'admit depresion',\n",
       " 'admit fault',\n",
       " 'admit haha',\n",
       " 'admit hospital',\n",
       " 'admit others',\n",
       " 'admit problem',\n",
       " 'admited',\n",
       " 'admited patients',\n",
       " 'admiting',\n",
       " 'admiting higher',\n",
       " 'admiting problemyou',\n",
       " 'admits',\n",
       " 'admits ate',\n",
       " 'adms',\n",
       " 'adms geting',\n",
       " 'adolescence',\n",
       " 'adolescence acording',\n",
       " 'adolescence makes',\n",
       " 'adolescence year',\n",
       " 'adolescent',\n",
       " 'adolescent department',\n",
       " 'adolescent depresion',\n",
       " 'adolescent may',\n",
       " 'adolescents',\n",
       " 'adolescents gay',\n",
       " 'adolescents higher',\n",
       " 'adolescents solution',\n",
       " 'adolescents university',\n",
       " 'adoption',\n",
       " 'adoption lgbqt',\n",
       " 'adorable',\n",
       " 'adorable af',\n",
       " 'adorable got',\n",
       " 'adorable quot',\n",
       " 'adres',\n",
       " 'adres bipolar',\n",
       " 'adres girl',\n",
       " 'adres mental',\n",
       " 'adres questions',\n",
       " 'adres university',\n",
       " 'adreses',\n",
       " 'adreses abe',\n",
       " 'adreses pendemic',\n",
       " 'adrian',\n",
       " 'adrian music',\n",
       " 'adriftand',\n",
       " 'adriftand frequently',\n",
       " 'ads',\n",
       " 'ads depresion',\n",
       " 'ads emoji',\n",
       " 'adulation',\n",
       " 'adulation demons',\n",
       " 'adult',\n",
       " 'adult comics',\n",
       " 'adult depresion',\n",
       " 'adult life',\n",
       " 'adult men',\n",
       " 'adults',\n",
       " 'adults adition',\n",
       " 'adults autism',\n",
       " 'adults diagnosis',\n",
       " 'adults hapy',\n",
       " 'adults nesdo',\n",
       " 'advance',\n",
       " 'advance hapy',\n",
       " 'advanced',\n",
       " 'advanced swear',\n",
       " 'advantage',\n",
       " 'advantage people',\n",
       " 'adversity',\n",
       " 'adversity like',\n",
       " 'advertising',\n",
       " 'advertising us',\n",
       " 'advice',\n",
       " 'advice esp',\n",
       " 'advice ever',\n",
       " 'advice fhrer',\n",
       " 'advice help',\n",
       " 'advice knowing',\n",
       " 'advice ofered',\n",
       " 'advice relapse',\n",
       " 'advice sufering',\n",
       " 'advisor',\n",
       " 'advisor ben',\n",
       " 'advisor depresion',\n",
       " 'advocate',\n",
       " 'advocate causes',\n",
       " 'ae',\n",
       " 'ae motion',\n",
       " 'ae today',\n",
       " 'aef',\n",
       " 'aef right',\n",
       " 'aeh',\n",
       " 'aeh bom',\n",
       " 'aerobics',\n",
       " 'aerobics strengthen',\n",
       " 'aesthetic',\n",
       " 'aesthetic depresion',\n",
       " 'af',\n",
       " 'af depresion',\n",
       " 'af marketer',\n",
       " 'af though',\n",
       " 'af twice',\n",
       " 'afect',\n",
       " 'afect anyone',\n",
       " 'afect beliefs',\n",
       " 'afect ch',\n",
       " 'afect levels',\n",
       " 'afect marks',\n",
       " 'afect milions',\n",
       " 'afect oughtibridge',\n",
       " 'afect people',\n",
       " 'afect qualityfrom',\n",
       " 'afect writing',\n",
       " 'afected',\n",
       " 'afected depresion',\n",
       " 'afected device',\n",
       " 'afected severe',\n",
       " 'afected sleping',\n",
       " 'afecting',\n",
       " 'afecting health',\n",
       " 'afective',\n",
       " 'afective disorder',\n",
       " 'afects',\n",
       " 'afects patients',\n",
       " 'afects person',\n",
       " 'afects productivity',\n",
       " 'afects us',\n",
       " 'afirmation',\n",
       " 'afirmation mantra',\n",
       " 'afirmations',\n",
       " 'afirmations via',\n",
       " 'afirming',\n",
       " 'afirming big',\n",
       " 'afloat',\n",
       " 'afonica',\n",
       " 'afonica fel',\n",
       " 'aford',\n",
       " 'aford bus',\n",
       " 'aford fucking',\n",
       " 'aford regular',\n",
       " 'aford time',\n",
       " 'afordable',\n",
       " 'afordable cure',\n",
       " 'aforementioned',\n",
       " 'aforementioned posts',\n",
       " 'afraid',\n",
       " 'afraid admit',\n",
       " 'afraid kil',\n",
       " 'afraid try',\n",
       " 'africa',\n",
       " 'africa bilion',\n",
       " 'africa ready',\n",
       " 'africa south',\n",
       " 'african',\n",
       " 'african americans',\n",
       " 'african drums',\n",
       " 'african sufer',\n",
       " 'afteral',\n",
       " 'afternon',\n",
       " 'afternon bite',\n",
       " 'afternon family',\n",
       " 'afternon friend',\n",
       " 'afternon laundry',\n",
       " 'afternon shift',\n",
       " 'afternon shop',\n",
       " 'age',\n",
       " 'age close',\n",
       " 'age gender',\n",
       " 'age geographical',\n",
       " 'age joined',\n",
       " 'age people',\n",
       " 'age raise',\n",
       " 'age wealth',\n",
       " 'age yoga',\n",
       " 'aged',\n",
       " 'aged fight',\n",
       " 'agencies',\n",
       " 'agencies want',\n",
       " 'agency',\n",
       " 'agency lunch',\n",
       " 'agency side',\n",
       " 'ages',\n",
       " 'ages god',\n",
       " 'ages researchers',\n",
       " 'aging',\n",
       " 'aging proces',\n",
       " 'aging wrinkles',\n",
       " 'agitation',\n",
       " 'agitation nervousnes',\n",
       " 'ago',\n",
       " 'ago destroyed',\n",
       " 'ago excuse',\n",
       " 'ago experiencing',\n",
       " 'ago gladly',\n",
       " 'ago goes',\n",
       " 'ago hapened',\n",
       " 'ago hapy',\n",
       " 'ago memes',\n",
       " 'ago scratching',\n",
       " 'ago show',\n",
       " 'ago since',\n",
       " 'ago speaking',\n",
       " 'ago tok',\n",
       " 'ago years',\n",
       " 'agony',\n",
       " 'agre',\n",
       " 'agre beautiful',\n",
       " 'agre disagre',\n",
       " 'agre heineken',\n",
       " 'agre luna',\n",
       " 'agre opinion',\n",
       " 'agre simon',\n",
       " 'agre though',\n",
       " 'agred',\n",
       " 'agred bulied',\n",
       " 'agred emoji',\n",
       " 'agred takes',\n",
       " 'agred working',\n",
       " 'agreing',\n",
       " 'agreing seo',\n",
       " 'agrements',\n",
       " 'agrements colectively',\n",
       " 'agresion',\n",
       " 'agresion never',\n",
       " 'agresive',\n",
       " 'agresive behavior',\n",
       " 'agresive marketing',\n",
       " 'agresive medication',\n",
       " 'agresively',\n",
       " 'agresively argumentative',\n",
       " 'agynathavasi',\n",
       " 'agynathavasi core',\n",
       " 'ah',\n",
       " 'ah back',\n",
       " 'ah depresion',\n",
       " 'ah feling',\n",
       " 'ah finaly',\n",
       " 'ah godnight',\n",
       " 'ah hear',\n",
       " 'ah hypocrisy',\n",
       " 'ah last',\n",
       " 'ah life',\n",
       " 'ah lok',\n",
       " 'ah never',\n",
       " 'ah okie',\n",
       " 'ah stuning',\n",
       " 'ah vision',\n",
       " 'ah wekend',\n",
       " 'ah wil',\n",
       " 'aha',\n",
       " 'aha inded',\n",
       " 'aha mostly',\n",
       " 'aha pet',\n",
       " 'ahah',\n",
       " 'ahah savior',\n",
       " 'ahaha',\n",
       " 'ahaha dude',\n",
       " 'ahahas',\n",
       " 'ahahas ryan',\n",
       " 'ahead',\n",
       " 'ahead admit',\n",
       " 'ahead darknes',\n",
       " 'ahead think',\n",
       " 'ahead ur',\n",
       " 'ahem',\n",
       " 'ahja',\n",
       " 'ahja liebe',\n",
       " 'ahold',\n",
       " 'ahold taking',\n",
       " 'ahoy',\n",
       " 'aidan',\n",
       " 'aidan les',\n",
       " 'aim',\n",
       " 'aim screname',\n",
       " 'aiming',\n",
       " 'aiming reduce',\n",
       " 'aims',\n",
       " 'aims help',\n",
       " 'aint',\n",
       " 'aint nothing',\n",
       " 'air',\n",
       " 'air con',\n",
       " 'air cut',\n",
       " 'air drops',\n",
       " 'air kep',\n",
       " 'airing',\n",
       " 'airing wek',\n",
       " 'airplane',\n",
       " 'airplane departure',\n",
       " 'airplane depresion',\n",
       " 'airplane early',\n",
       " 'airplane intense',\n",
       " 'airplay',\n",
       " 'airplay anyway',\n",
       " 'airport',\n",
       " 'airport awaiting',\n",
       " 'airport hola',\n",
       " 'airport husband',\n",
       " 'airport se',\n",
       " 'aish',\n",
       " 'aish achievements',\n",
       " 'aish fans',\n",
       " 'ait',\n",
       " 'ait today',\n",
       " 'aj',\n",
       " 'aj pala',\n",
       " 'ak',\n",
       " 'ak board',\n",
       " 'aka',\n",
       " 'aka conciquences',\n",
       " 'aka democratic',\n",
       " 'aka depresion',\n",
       " 'ako',\n",
       " 'ako ng',\n",
       " 'ako within',\n",
       " 'akp',\n",
       " 'akp turkey',\n",
       " 'al',\n",
       " 'al absolutely',\n",
       " 'al ages',\n",
       " 'al al',\n",
       " 'al albums',\n",
       " 'al along',\n",
       " 'al also',\n",
       " 'al apathy',\n",
       " 'al asholes',\n",
       " 'al asked',\n",
       " 'al aware',\n",
       " 'al back',\n",
       " 'al bad',\n",
       " 'al balance',\n",
       " 'al believe',\n",
       " 'al bg',\n",
       " 'al bitches',\n",
       " 'al blends',\n",
       " 'al blue',\n",
       " 'al bq',\n",
       " 'al bright',\n",
       " 'al bulying',\n",
       " 'al cast',\n",
       " 'al celebz',\n",
       " 'al charging',\n",
       " 'al cheap',\n",
       " 'al clothes',\n",
       " 'al coats',\n",
       " 'al coment',\n",
       " 'al comon',\n",
       " 'al corn',\n",
       " 'al cost',\n",
       " 'al costing',\n",
       " 'al could',\n",
       " 'al creative',\n",
       " 'al cured',\n",
       " 'al day',\n",
       " 'al depresion',\n",
       " 'al deserve',\n",
       " 'al diference',\n",
       " 'al done',\n",
       " 'al dope',\n",
       " 'al drama',\n",
       " 'al easy',\n",
       " 'al else',\n",
       " 'al emoji',\n",
       " 'al equipment',\n",
       " 'al exams',\n",
       " 'al fans',\n",
       " 'al far',\n",
       " 'al fine',\n",
       " 'al forgot',\n",
       " 'al fun',\n",
       " 'al furies',\n",
       " 'al gadgets',\n",
       " 'al geting',\n",
       " 'al girls',\n",
       " 'al glory',\n",
       " 'al god',\n",
       " 'al goes',\n",
       " 'al going',\n",
       " 'al gone',\n",
       " 'al gop',\n",
       " 'al got',\n",
       " 'al grandma',\n",
       " 'al gravy',\n",
       " 'al great',\n",
       " 'al greatnes',\n",
       " 'al guys',\n",
       " 'al hands',\n",
       " 'al hapened',\n",
       " 'al hapens',\n",
       " 'al hapy',\n",
       " 'al hawai',\n",
       " 'al headed',\n",
       " 'al help',\n",
       " 'al hiding',\n",
       " 'al hours',\n",
       " 'al hurt',\n",
       " 'al incoming',\n",
       " 'al increased',\n",
       " 'al inputs',\n",
       " 'al intelect',\n",
       " 'al isues',\n",
       " 'al joking',\n",
       " 'al junk',\n",
       " 'al kinds',\n",
       " 'al know',\n",
       " 'al ladies',\n",
       " 'al later',\n",
       " 'al levels',\n",
       " 'al like',\n",
       " 'al listen',\n",
       " 'al living',\n",
       " 'al lost',\n",
       " 'al love',\n",
       " 'al loved',\n",
       " 'al loving',\n",
       " 'al lows',\n",
       " 'al mad',\n",
       " 'al make',\n",
       " 'al material',\n",
       " 'al mates',\n",
       " 'al mental',\n",
       " 'al midle',\n",
       " 'al morning',\n",
       " 'al motherly',\n",
       " 'al moved',\n",
       " 'al much',\n",
       " 'al necesary',\n",
       " 'al new',\n",
       " 'al next',\n",
       " 'al night',\n",
       " 'al nostalgic',\n",
       " 'al organised',\n",
       " 'al pased',\n",
       " 'al paths',\n",
       " 'al people',\n",
       " 'al persistent',\n",
       " 'al pets',\n",
       " 'al pictures',\n",
       " 'al place',\n",
       " 'al points',\n",
       " 'al prep',\n",
       " 'al problems',\n",
       " 'al psych',\n",
       " 'al pts',\n",
       " 'al push',\n",
       " 'al quite',\n",
       " 'al quot',\n",
       " 'al rapha',\n",
       " 'al read',\n",
       " 'al realy',\n",
       " 'al refuse',\n",
       " 'al relationships',\n",
       " 'al relative',\n",
       " 'al research',\n",
       " 'al rewire',\n",
       " 'al right',\n",
       " 'al rise',\n",
       " 'al robed',\n",
       " 'al rocks',\n",
       " 'al say',\n",
       " 'al saying',\n",
       " 'al screngrab',\n",
       " 'al second',\n",
       " 'al secondly',\n",
       " 'al self',\n",
       " 'al sending',\n",
       " 'al sesions',\n",
       " 'al set',\n",
       " 'al shal',\n",
       " 'al shows',\n",
       " 'al slide',\n",
       " 'al smaler',\n",
       " 'al smiles',\n",
       " 'al social',\n",
       " 'al son',\n",
       " 'al sorted',\n",
       " 'al sorts',\n",
       " 'al spend',\n",
       " 'al springy',\n",
       " 'al stand',\n",
       " 'al start',\n",
       " 'al stil',\n",
       " 'al stres',\n",
       " 'al strugle',\n",
       " 'al stufed',\n",
       " 'al suces',\n",
       " 'al sufer',\n",
       " 'al suprises',\n",
       " 'al sure',\n",
       " 'al take',\n",
       " 'al ten',\n",
       " 'al tens',\n",
       " 'al th',\n",
       " 'al thanks',\n",
       " 'al therapists',\n",
       " 'al things',\n",
       " 'al think',\n",
       " 'al thre',\n",
       " 'al time',\n",
       " 'al together',\n",
       " 'al tomorow',\n",
       " 'al town',\n",
       " 'al trying',\n",
       " 'al tshirts',\n",
       " 'al twets',\n",
       " 'al twilight',\n",
       " 'al twiter',\n",
       " 'al types',\n",
       " 'al used',\n",
       " 'al wana',\n",
       " 'al want',\n",
       " 'al watching',\n",
       " 'al way',\n",
       " 'al wekend',\n",
       " 'al wel',\n",
       " 'al wet',\n",
       " 'al wil',\n",
       " 'al wonderful',\n",
       " 'al wories',\n",
       " 'al work',\n",
       " 'al world',\n",
       " 'al worth',\n",
       " 'alah',\n",
       " 'alan',\n",
       " 'alan tate',\n",
       " 'alarming',\n",
       " 'alarming rise',\n",
       " 'alas',\n",
       " 'alas depresion',\n",
       " 'alay',\n",
       " 'alay depresion',\n",
       " 'alay malaise',\n",
       " 'albany',\n",
       " 'albany going',\n",
       " 'albeit',\n",
       " 'albeit litle',\n",
       " 'albino',\n",
       " 'albino structure',\n",
       " 'album',\n",
       " 'album artist',\n",
       " 'album bateman',\n",
       " 'album come',\n",
       " 'album concerns',\n",
       " 'album cover',\n",
       " 'album drops',\n",
       " 'album forgoten',\n",
       " 'album keping',\n",
       " 'album like',\n",
       " 'album listen',\n",
       " 'album morn',\n",
       " 'album saturdays',\n",
       " 'album say',\n",
       " 'album songs',\n",
       " 'albums',\n",
       " 'albums mania',\n",
       " 'alcohol',\n",
       " 'alcohol abuse',\n",
       " 'alcohol adiction',\n",
       " 'alcohol cocaine',\n",
       " 'alcohol drug',\n",
       " 'alcohol easy',\n",
       " 'alcohol poisoning',\n",
       " 'alcoholic',\n",
       " 'alcoholic cros',\n",
       " 'alcoholic never',\n",
       " 'alcoholic ur',\n",
       " 'alcoholism',\n",
       " 'alcoholism marijuana',\n",
       " 'alcoholism potentialy',\n",
       " 'alen',\n",
       " 'alergies',\n",
       " 'alergies depresion',\n",
       " 'alergies leaving',\n",
       " 'alert',\n",
       " 'alert active',\n",
       " 'alert sudenly',\n",
       " 'alerts',\n",
       " 'alerts next',\n",
       " 'aleviate',\n",
       " 'aleviate anxiety',\n",
       " 'aleviate depresion',\n",
       " 'aleviate problems',\n",
       " 'aleviated',\n",
       " 'aleviated depresive',\n",
       " 'alex',\n",
       " 'alex fine',\n",
       " 'alex proven',\n",
       " 'alexa',\n",
       " 'alexa waiting',\n",
       " 'alexander',\n",
       " 'alexander armstrong',\n",
       " 'algorithm',\n",
       " 'algorithm strip',\n",
       " 'ali',\n",
       " 'ali bought',\n",
       " 'alias',\n",
       " 'alien',\n",
       " 'alien posible',\n",
       " 'aliens',\n",
       " 'aliens world',\n",
       " 'alitle',\n",
       " 'alitle tired',\n",
       " 'alive',\n",
       " 'alive another',\n",
       " 'alive atention',\n",
       " 'alive care',\n",
       " 'alive emoji',\n",
       " 'alive loving',\n",
       " 'alkermes',\n",
       " 'alkermes depresion',\n",
       " 'almir',\n",
       " 'almir kristin',\n",
       " 'almost',\n",
       " 'almost always',\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfid3.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60138d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb3.fit(vector3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b567109f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.59542864, -10.74808071, -10.78606749, ..., -11.01818795,\n",
       "        -10.76319344, -10.73295398]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "021fe3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.Series(nb3.coef_[0], index = tfid3.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49bc93c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hapy hapy       -11.018188\n",
       "film trip       -11.018188\n",
       "filming         -11.018188\n",
       "filming media   -11.018188\n",
       "films realy     -11.018188\n",
       "                   ...    \n",
       "face             -7.206142\n",
       "emoji            -6.840789\n",
       "nan              -6.700700\n",
       "anxiety          -6.683061\n",
       "depresion        -5.266215\n",
       "Length: 41233, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.sort_values()\n",
    "\n",
    "#agregar palabras a las stopwords , por ejemplo 'twitter', 'com'\n",
    "#agregar precision, accuracy, recall , f1 , etc\n",
    "#min, max \n",
    "#max_features:overfitting? ~ regularizacion\n",
    "\n",
    "#to do: traduccion?\n",
    "#red de deeplearning para buscar mejor score\n",
    "#testeos\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd61f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463bdaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
