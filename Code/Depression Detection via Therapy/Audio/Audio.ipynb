{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a04a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5be5c7",
   "metadata": {},
   "source": [
    "#Preparing Data\n",
    "we will get rid of unused columns which are irrelevant for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1be2f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = np.array(pd.read_csv('/Users/joacosoulez/Downloads/transcriptions/dev_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
    "dataset2 = np.array(pd.read_csv('/Users/joacosoulez/Downloads/transcriptions/full_test_split.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n",
    "dataset3 = np.array(pd.read_csv('/Users/joacosoulez/Downloads/transcriptions/train_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6492b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate((dataset1, np.concatenate((dataset2, dataset3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a871237",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((1,74))\n",
    "Y_train = []\n",
    "\n",
    "X_test = np.zeros((1,74))\n",
    "Y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "322c1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(X):\n",
    "    for i in range(X.shape[0]):\n",
    "        if(X[i,1] == 0):\n",
    "            X[i,0] = 0\n",
    "            for j in range(7):\n",
    "                X[i,j+1] = 0\n",
    "    X = np.array(X)\n",
    "    X = np.average(X, axis = 0)\n",
    "    X = np.array(X.reshape(1, -1))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "67872793",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset2)):\n",
    "        fileName = \"/Users/joacosoulez/Desktop/audio/Covarep/\"+str(i)+\"_COVAREP.csv\"\n",
    "        data = pd.read_csv(fileName,header = None)\n",
    "        X_temp = data.iloc[:,:].values\n",
    "        X_temp = make_data(X_temp)\n",
    "        X_test = np.concatenate((X_test,X_temp),0)\n",
    "        for n in range(len(dataset2)):\n",
    "            if dataset2[n][0] == i:\n",
    "                Y_test.append(dataset2[n][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8def2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.delete(X_test,0,0)\n",
    "Y_test = np.array(Y_test)\n",
    "count_0 = 0\n",
    "count_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bbbf1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset3)):\n",
    "        fileName = \"/Users/joacosoulez/Desktop/audio/Covarep/\"+str(i)+\"_COVAREP.csv\"\n",
    "        data = pd.read_csv(fileName,header = None)\n",
    "\n",
    "for n in range(len(dataset3)):\n",
    "    if(dataset3[n][1] == 0):\n",
    "      count_0 +=1\n",
    "      if(count_0<27):\n",
    "        X_temp = data.iloc[:,:].values\n",
    "        X_temp = make_data(X_temp)\n",
    "        X_train = np.concatenate((X_train,X_temp),0)\n",
    "        if dataset3[n][0] == i:\n",
    "            Y_train.append(dataset3[n][1])\n",
    "    else:\n",
    "      count_1 +=1\n",
    "      if(count_1<27):\n",
    "        X_temp = data.iloc[:,:].values\n",
    "        X_temp = make_data(X_temp)\n",
    "        X_train = np.concatenate((X_train,X_temp),0)\n",
    "        if dataset3[n][0] == i:\n",
    "            Y_train.append(dataset3[n][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "95c7392e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8ee3b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0    \n",
    "\n",
    "for i in range(len(dataset3)):\n",
    "    fileName = \"/Users/joacosoulez/Desktop/audio/Covarep/\"+str(i)+\"_COVAREP.csv\"\n",
    "    data = pd.read_csv(fileName,header = None)\n",
    "    for n in range(len(dataset1)):\n",
    "        if(dataset1[n][1] == 0):\n",
    "            count_0 += 1\n",
    "            if(count_0<27):\n",
    "                X_temp = data.iloc[:,:].values\n",
    "                X_temp = make_data(X_temp)\n",
    "                X_train = np.concatenate((X_train,X_temp),0)\n",
    "                if dataset3[n][0] == i:\n",
    "                    Y_train.append(dataset1[n][1])\n",
    "            else:\n",
    "              count_1+= 1\n",
    "              if(count_1<27):\n",
    "                X_temp = data.iloc[:,:].values\n",
    "                X_temp = make_data(X_temp)\n",
    "                X_train = np.concatenate((X_train,X_temp),0)\n",
    "                if dataset3[n][0] == i:\n",
    "                    Y_train.append(dataset1[n][1])\n",
    "    \n",
    "\n",
    "X_train = np.delete(X_train,0,0)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "236f8d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141177d",
   "metadata": {},
   "source": [
    "##Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=2000, decay_rate=0.5)\n",
    "    adam = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model.add(Conv1D(60, 10, input_shape = (40000, 74), activation = 'relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 3))\n",
    "    model.add(Conv1D(30, 5, activation = 'relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 3))\n",
    "    model.add(Conv1D(15, 5, activation = 'relu',dropout(0.5)))\n",
    "    model.add(MaxPooling1D(pool_size = 3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "    cmodel.compile(\n",
    "      optimizer=adam,\n",
    "      loss=\"binary_crossentropy\",\n",
    "      metrics=['accuracy', 'AUC','Precision','Recall'])\n",
    "  return model\n",
    "  \n",
    "  def modelFit(self, X, Y, epoch = 10):\n",
    "    self.classifier.fit(X, Y, epochs=epoch)\n",
    "\n",
    "  def modelPredict(self, X):\n",
    "    return self.classifier.predict(X)\n",
    "\n",
    "model = CNN_audio()\n",
    "model.modelFit(X_upsample, Y_upsample, 1)\n",
    "Y_pred = Thresholding(model.modelPredict(X_test), 0.8)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
